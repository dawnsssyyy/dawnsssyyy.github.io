<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <title>AI Risk Framework (Paginated)</title>
  <style>
    body {
      font-family: 'Segoe UI', sans-serif;
      margin: 20px;
      background-color: #f9f9f9;
      color: #333;
      line-height: 1.6;
    }
    /* 페이지 하나하나를 구분 */
    /* 페이지 기본 스타일 */
.page {
  display: none; /* 기본적으로 숨김 */
  margin: 20px 0;
}

/* 페이지 내 제목 색상 */
.page h1,
.page h2,
.page h3 {
  color: #4CAF50;
}

/* 내비게이션 스타일 (가운데 정렬) */
.navigation {
  text-align: center;
  margin-top: 30px;
}
.navigation a {
  font-size: 18px;
  color: #4CAF50;
  text-decoration: none;
  cursor: pointer;
}
.navigation a:hover {
  text-decoration: underline;
}

/* 연구 제목 */
.research-title {
  font-size: 25pt;    /* 크게 */
  font-weight: bold;
  margin-bottom: 20px;
}

/* 콘텐츠 박스 */
.content-box {
  border: 2px solid #4CAF50;
  background-color: #fff;
  padding: 20px;
  font-size: 18px;
  line-height: 1.8;
  border-radius: 8px;
  margin-bottom: 20px;
}

/* 강조 텍스트 */
.highlight {
  font-size: 20px;    /* 강조할 문장은 더 크고 굵게 */
  font-weight: bold;
  color: #000;
}

/* 소개 텍스트 */
.intro-text {
  font-size: 23px;
  margin-bottom: 20px;
}

/* 단계 목록 스타일 */
.steps-list {
  font-size: 18px;
  line-height: 1.8;
  padding-left: 20px;
  margin: 20px 0;
}

/* 단계별 설명 박스 (uniform style) */
.step-box {
  background-color: #f2f2f2;
  border: 1px solid #ddd;
  border-radius: 8px;
  padding: 15px;
  margin-bottom: 20px;
}

/* 각 단계 제목 */
.step-title {
  font-size: 22px;
  font-weight: bold;
  margin-bottom: 10px;
  color: #333;
}

/* 단계 설명 */
.step-desc {
  font-size: 18px;
  color: #555;
}

/* 위험 테이블 스타일 */
.risk-table {
  width: 100%;
  border-collapse: collapse;
  margin-top: 10px;
}
.risk-table th,
.risk-table td {
  border: 1px solid #ddd;
  padding: 10px;
  font-size: 18px;
}
.risk-table th {
  background-color: #4CAF50;
  color: #fff;
  font-size: 20px;
}

/* 시나리오 설명 박스 */
.scenario-box {
  background-color: #fff;
  border: 2px solid #4CAF50;
  border-radius: 8px;
  padding: 20px;
  font-size: 18px;
  line-height: 1.8;
  margin-bottom: 20px;
}

/* 다음 링크 스타일 */
.next-link {
  font-size: 18px;
  color: #4CAF50;
  text-decoration: none;
  cursor: pointer;
}
.next-link:hover {
  text-decoration: underline;
}
.large-text {
  font-size: 1.25rem;    /* 예: 기본보다 25% 크게 */
  line-height: 1.6;      /* 읽기 편한 줄 간격 */
  margin-bottom: 1em;
}
.video-container {
  max-width: 800px;    /* 원하는 최대너비 */
  margin: 20px auto;   /* 위아래 여백, 중앙정렬 */
}
.video-container video {
  display: block;
}

</style>

  <script>
    let currentPage = 0;

    // 특정 페이지(index)만 보이게 하고, 나머지는 숨김
    function showPage(pageIndex) {
      const pages = document.getElementsByClassName('page');
      for (let i = 0; i < pages.length; i++) {
        pages[i].style.display = 'none';
      }
      if (pages[pageIndex]) {
        pages[pageIndex].style.display = 'block';
        currentPage = pageIndex;
      }
    }
    // "[다음]" 버튼 클릭 시 다음 페이지로 이동
    function nextPage() {
      const pages = document.getElementsByClassName('page');
      if (currentPage < pages.length - 1) {
        showPage(currentPage + 1);
      }
    }

    window.onload = function() {
      // 페이지가 로드되면 첫 번째 페이지부터 보여줌
      showPage(0);
    }
  </script>
</head>
<body>
  <!-- 
    예시로, PDF에 등장하는 '[다음]' 문구를 기준으로
    여러 <div class="page">로 나누었습니다.
    실제로는 PDF 전체 텍스트를 필요한 만큼 잘라 넣으시면 됩니다.
  -->

<!-- 페이지 1 (PDF의 첫 부분부터 첫 [다음] 전까지) -->
<div class="page">
  <h2>AI Risk Framework 이용자 설문조사</h2>
  
  <!-- 본 연구 목적 제목: 더 크게, 굵게 -->
  <h2>본 연구 목적</h2>
 
  <!-- 본문 내용을 박스 형태로 감싸고, 글씨 크기 및 간격을 키움 -->
  <div class="content-box">
    <p>
      인공지능이 빠르게 발전하면서 그로 인한 위험도 증가하고 있습니다. 예를 들어, 인공지능은 허위 정보 생성, 개인정보 침해, 독성 콘텐츠 노출, 편향된 결과 등으로 다양한 위험을 유발합니다.<br><br>
      인공지능 제품/서비스를 개발할 때는 인공지능의 잠재적인 위험을 반드시 인식해야 합니다. 인공지능 위험을 인지하고 이를 최소화하기 위한 노력을 해야 사용자와 사회에 대한 피해를 줄일 수 있고, 제품/서비스 출시 이후에도 책임있는 관리와 신속한 문제 해결이 가능합니다. 그렇지 않을 경우 여러 법적 책임을 지게 되거나 제품/서비스 출시가 중단될 수 있습니다.<br><br>
      하지만 각 인공지능 제품/서비스가 유발하는 위험은 파악하는 것은 어렵습니다. 
	또한 그 위험들을 파악한다고 하더라도 한정된 자원으로 모든 위험을 한꺼번에 대응하기 어렵기 때문에, 
	개발하는 인공지능 제품/서비스에 따른 위험의 우선순위를 파악하여 대응하여야 하는데, 여러 위험 중 무엇이 더 중요한 위험인지 아는 것은 쉽지 않습니다. <br><br>
      그렇기 때문에 개발하는 제품/서비스의 특성에 따라 가장 심각하고 즉각적인 영향을 미칠 수 있는 위험부터 제시해주는 프레임워크가 필요합니다. 이에 저희는 제품/서비스 특성에 따라 인공지능 위험의 우선순위를 정해 보여주는 AI Risk Framework를 개발하였습니다.<br><br>
      <span class="highlight">본 프레임워크는 ‘기사’를 활용하여 ‘제품/서비스별 AI 위험’의 발생 빈도와 위해성을 측정하여 만들어졌으며, 제품/서비스 특성을 선택하면 위험을 ‘우선순위별’로 볼 수 있도록 제공합니다.</span><br><br>
      최근 기사를 기반으로 인공지능 제품/서비스 특성에 따라 위험이 발생한 빈도와 위해성을 수치화하고, 이를 기반으로 순위를 도출함으로써 실무자가 효과적이고 직관적으로 위험을 식별하고 관리할 수 있도록 돕고자 합니다.
    </p>
  </div>
  
  <!-- 하단 네비게이션: 가운데 정렬, 단순 "[다음]" 텍스트 링크 -->
  <div class="navigation">
    <a class="next-link" onclick="nextPage()">[다음]</a>
  </div>
</div>


  <!-- 페이지 2 (두 번째 [다음] 전까지) -->
  <div class="page">
    <h2>🚩 AI Risk Framework 구축</h2>
    <p class="intro-text">우리의 AI Risk Framework는 다음과 같이 구축되었습니다.</p>

    <ul class="steps-list">
      <li class="step-box">
        <h3 class="step-title">1) 제품 및 서비스를 7개 특성으로 유형화</h3>
        <p class="step-desc">
          특성: (1) 적용 분야, (2) 의사결정 지원의 중요도, (3) 데이터 민감도, (4) 시스템의 설명가능성, (5) 의사결정 자동화 수준, (6) 사용대상, (7) 기술적 특징
        </p>
      </li>
      <li class="step-box">
        <h3 class="step-title">2) 기사 분석 및 위험 측정</h3>
        <p class="step-desc">
          일정 기간 동안 인공지능 위험 관련 기사를 크롤링한 후, 해당 기사 내용을 바탕으로 제품/서비스 특성과 위험 요소 간의 동시 등장 빈도(likelihood)와 피해 정도(Severity)를 정량적으로 계산합니다. <br>
	  이는 bottom-up 방식으로, 일반인이 인지하는 위험에 근거합니다.
        </p>
      </li>
      <li class="step-box">
        <h3 class="step-title">3) AI Risk Framework Table 완성</h3>
        <p class="step-desc">
          이 테이블에서 각 위험 요소와 제품/서비스 특성 사이의 수치는 ‘위험의 정도’를 나타냅니다.<br>
            예: 기술적으로 ‘D29 인식’ 특징이 있을 때, ‘부당한 차별과 허위진술 위험(R1)’은 2 정도 있습니다. <br>
          위험 요소 합산 값이 클수록 해당 위험은 더 중요하게 고려되어야 합니다.
        </p>
	<div class="image-container">
      <img
        src="image.png"
        alt="AI Risk Framework Table 예시"
        style="max-width: 100%; height: auto; display: block; margin: 20px auto;"
      />
    </div>
      </li>
      <li class="step-box">
        <h3 class="step-title">4) AI Risk Framework Table 활용</h3>
        <p class="step-desc">
          제품/서비스의 특성을 선택하면, 위험 요소별 합산값을 통해 중요한 AI 위험을 파악할 수 있습니다. (같은 행에서 합산 값이 클수록 더 중요한 위험으로 간주됩니다.)
        </p>
      </li>
    </ul>

    <div class="navigation">
      <a class="next-link" onclick="nextPage()">[다음]</a>
    </div>
  </div>

  <!-- 페이지 3 (세 번째 [다음] 전까지) -->
  <div class="page">
    <h2>실험에 대한 설명</h2>

   <p class="large-text">
    <strong>세 개의 AI 제품/서비스 시나리오</strong>에 대해서<br><br>
    <strong>(1) AI Risk Framework를 이용해 위험요소를 찾아보고</strong><br><br>
    <strong>(2) 상위 위험요소 3개에 대해서 추가적인 설명을 제공합니다.</strong><br><br>
    이제 본격적으로 시나리오를 보여드리겠습니다.
  </p>
    <!-- ...이후 내용... -->
    <div class="navigation">
      <a onclick="nextPage()">[다음]</a>
    </div>
  </div>

    <!-- 페이지 4  -->
<div class="page">
  <h2>🚩 첫 번째 시나리오: 개인 맞춤형 보험 상품 추천 및 리스크 관리 시스템</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
      <strong>금융 및 보험회사</strong> "스마트보험"은 AI 기반의 개인 맞춤형 보험 추천 및 리스크 관리 시스템을 구축했습니다. <br>
     이 시스템은 고객의 재정 상태, 생활 습관, 건강 정보와 같이 민감하고 개인적인 데이터를 바탕으로 보험 가입 여부 및 가입 조건을 추천합니다. <br>
    </p>
    <p>
      AI는 머신러닝과 지식구조를 활용하여 고객별로 미래의 리스크를 정확하게 예측하며, 고객에게 가장 적합한 보험상품을 제안합니다. <br>
     시스템은 고객의 <strong>건강 상태, 재정 상황, 직업군 등의 민감한 정보를 종합적으로 분석</strong>하여 <strong>생명, 안전, 기본권 등 중요한 인간 권리에 영향을 줄 수 있는 핵심 의사결정을 지원</strong>합니다.
    </p>
    <p>
      이러한 AI 시스템은 <strong>설명 가능한 인터페이스를 제공</strong>하여 고객 및 감독 기관이 의사결정 이유와 과정을 이해할 수 있도록 돕습니다. 모델이 복잡하더라도 별도의 설명 인터페이스와 사후 분석을 통해 공정성과 투명성을 검증합니다.
    </p>
    <p>
      또한, AI 시스템은 높은 자동화 수준으로 운영되지만, <strong>사람은 의사결정을 모니터링하며 필요시 즉각 개입하는 중간 자율도</strong>를 유지하여, 과도한 불리한 조건이 제시될 경우 공정성을 보장합니다.
    </p>
  </div>

  <!-- 단계별 설명 박스 1: 특성 선택 -->
  <div class="step-box">
    <h3>1️⃣ 이 서비스의 특성 요소를 다음과 같이 선택합니다.</h3>
    <ul class="step-desc">
      <li>금융·보험업에 적용된다.</li>
      <li>핵심적인 의사결정을 지원한다.</li>
      <li>민감한 정보를 사용한다.</li>
      <li>설명 인터페이스를 포함한다.</li>
      <li>인간이 모니터링하며 필요시 개입한다.</li>
      <li>개인화, 예측, 지식구조를 위한 추론 기술을 사용한다.</li>
    </ul>
    
	    <iframe width="560" height="315" src="https://www.youtube.com/embed/_eEJEja_1Kg?si=TrAolZt14P0cqUH5" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

    
	  
  </div>

  <!-- 단계별 설명 박스 2: 위험 점수가 높은 상위 3개 위험은 다음과 같습니다. -->
  <div class="step-box">
    <h3>2️⃣ 점수가 높은 상위 3개 위험은 다음과 같습니다.  </h3>
    <table class="risk-table">
      <thead>
        <tr>
          <th>순위</th>
          <th>위험</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>1</th>
          <td><strong>R22: 투명성이나 해석 가능성 부족</strong></td>
        </tr>
        <tr>
          <th>2</th>
          <td><strong>R6: 허위 또는 오해의 소지가 있는 정보</strong></td>
        </tr>
        <tr>
          <th>2</th>
          <td><strong>R8: 허위 정보, 감시 및 대규모 영향력</strong></td>
        </tr>
      </tbody>
    </table>
  </div>
    <!-- ...이후 내용... -->
    <div class="navigation">
      <a onclick="nextPage()">[다음]</a>
    </div>
</div>


    <!-- 페이지 5  -->
<div class="page">
  <h2>첫 번째 시나리오의 상위 3개 위험은 다음과 같습니다.</h2> <br><br>
	각 위험의 대응 방안에 따라서 인공지능 제품/서비스의 설계를 변경하는 방법도 고려할 수 있습니다. (예: 인공지능의 자율도를 낮추도록 변경) <br><br>

  <h2>첫 번째 위험: 투명성과 해석가능성 부족</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 인간에게 이해되지 않는 방식으로 작동할 때, 이를 "투명성 또는 해석 가능성 부족" 문제라고 한다. <br>
	이러한 문제는 AI가 의사결정을 내리는 과정이 불분명하거나 복잡하여 사용자, 개발자, 규제 당국 등이 그 판단 근거를 파악하기 어려운 상황에서 발생한다. <br>
	특히 딥러닝 기반 모델과 같이 복잡한 구조를 가진 AI 시스템은 "블랙박스"처럼 작동하여, 결과가 왜 도출되었는지 설명하기 어렵다. 이는 신뢰성 저하, 책임소재 불분명, 편향 감지의 어려움 등 다양한 위험을 초래할 수 있다. 
    </p>
    <p>
	예를 들어, 스마트보험의 AI 시스템은 고객의 건강검진 기록, 소비 패턴, 위치 기반 생활습관 데이터를 종합 분석해 ‘심혈관 질환 고위험군’으로 분류된 고객에게 특정 보험 상품을 추천했다.<br>
	그러나 고객은 자신이 왜 고위험군으로 판단되었는지, 어떤 요인이 보험료 인상에 영향을 미쳤는지를 이해할 수 없었다. <br>
	심지어 고객의 건강검진 수치가 평균 범위임에도 불구하고, AI가 “직업군 스트레스 지수”를 과도하게 반영한 결과였다. <br>
	이처럼 AI의 의사결정 근거가 불투명하면, 고객은 차별적 대우를 받았다고 느끼며, 감독기관도 합리성을 검증하기 어렵다.	
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 모델 해석 가능성 도구 활용</strong></h3>
        <p class="step-desc">
			SHAP(Shapley Additive Explanations) 또는 LIME(Local Interpretable Model-agnostic Explanations) 등 해석 가능한 AI 기법을 적용하여, “보험료 결정에 기여한 주요 요인”을 시각적으로 제공한다.
예컨대, 고객이 ‘보험료가 높게 책정된 이유’를 그래프로 확인할 수 있도록 하고, 건강정보, 재정정보, 직업정보별 기여도를 표시한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 투명성 문서화 및 보고 체계 구축</strong></h3>
        <p class="step-desc">
			스마트보험은 각 AI 모델별로 Model Card를 작성하여, 사용 데이터, 모델 구조, 신뢰도 한계, 공정성 평가결과를 명시한다. 고객과 감독기관이 이를 열람할 수 있는 ‘설명 포털’을 운영해, AI 판단 과정의 투명성을 확보한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 인간 감독 및 정기적인 감사 실시</strong></h3>
        <p class="step-desc">
			보험 언더라이팅 담당자가 AI의 추천 결과를 검토하고, 이상치나 편향이 의심되는 사례를 주기적으로 샘플링하여 AI 공정성 감사(AI fairness audit)를 실시한다. 내부 ‘AI 윤리위원회’가 감사 결과를 평가하고, 편향 요인이 발견되면 즉시 모델 재훈련을 지시한다.
        </p>
  </div>
  <br><br>
  <h2>두 번째 위험: 허위 또는 오해를 유발하는 정보</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 잘못된 정보나 오해를 유발하는 내용을 생성하거나 제공하는 경우, 이는 "허위 또는 오해를 유발하는 정보" 문제에 해당한다. <br>
	이러한 문제는 AI가 부정확한 데이터를 학습했거나, 편향된 알고리즘을 사용했거나, 신뢰할 수 없는 출처를 기반으로 정보를 생성할 때 발생할 수 있다. <br>
	이는 가짜 뉴스, 조작된 이미지 및 영상, 잘못된 의료 또는 금융 정보 제공 등의 형태로 나타나며, 개인과 사회에 심각한 영향을 미칠 수 있다.<br>
    </p>
    <p>
	예를 들어, AI 시스템이 학습한 데이터 중 일부는 오래된 건강정보 통계(예: 2010년대 기준 BMI 위험군 데이터)를 포함하고 있었다. <br> 
이에 따라, 최신 의료지식과 맞지 않는 기준을 적용해 ‘비만 위험’이 과대평가된 고객에게 불필요하게 높은 보험료를 제시했다. <br>
또한 시스템은 고객에게 “당신은 향후 5년 내 심혈관질환 발병 확률이 80%입니다”라는 메시지를 표시했지만, 실제로는 단순히 유사 직업군 평균값을 적용한 것이었다. <br>
이런 부정확하거나 과장된 정보는 고객의 공포심을 유발하고, 오해를 통해 불리한 의사결정을 하게 만든다.  <br>
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 신뢰할 수 있는 데이터와 검증 기법 활용</strong></h3>
        <p class="step-desc">
			학습 데이터는 공인된 의료 통계·금융 데이터베이스로 제한하고, 주기적으로 최신 버전으로 업데이트한다. 데이터 검증팀이 데이터 품질 점검 보고서(Data Quality Report)를 발행해 정확성과 시의성을 관리한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 팩트 체크 및 콘텐츠 검열 시스템 도입</strong></h3>
        <p class="step-desc">
			고객에게 제공되는 위험 예측 결과는 의료·보험 전문가의 사전 검토 절차를 거쳐야 하며, AI 예측과 전문가 판단이 불일치할 경우 고객에게 “예측 오차 범위”를 명시한다. 예를 들어, "AI 예측은 80%이지만, 전문가 검토 결과 오차 가능성이 15%로 확인됨"이라고 표시한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 투명성 강화 및 책임성 확보</strong></h3>
        <p class="step-desc">
			AI가 제시하는 모든 분석 결과에 데이터 출처, 모델 버전, 업데이트 시점을 표시하고, 고객이 오류를 발견하면 ‘AI 판단 재검토 요청’을 즉시 제출할 수 있도록 절차를 마련한다.
재검토 결과는 시스템 개선에 반영되어, 신뢰성을 강화한다.
		
        </p>
  </div>

   <br><br>
  <h2>세 번째 위험: 허위 정보, 감시 및 대규모 영향력</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 허위 정보를 대량으로 생성하거나, 사람들의 행동을 감시하고 분석하거나, 특정한 의견이나 결정을 조작하는 데 사용될 때, 이는 "허위 정보, 감시, 대규모 영향력 행사" 문제에 해당한다. <br>
	이러한 문제는 AI가 사회 여론을 조작하는 데 악용되거나, 대규모 감시 시스템으로 개인의 자유를 침해하거나, 특정 집단을 선동하거나 억압하는 데 활용될 때 발생한다. <br>
	이는 민주적 의사결정을 왜곡하고, 표현의 자유를 위협하며, 공정한 사회 구조를 해칠 위험이 있다. <br>
    </p>
    <p>
	스마트보험은 고객의 스마트워치, 위치정보, 결제 데이터를 종합 분석해 건강 습관을 점수화하고, 이를 바탕으로 ‘보험 할인·가산율’을 조정했다.<br>
하지만 고객이 동의하지 않은 데이터까지 감시적으로 수집되어, 개인의 행동이 지속적으로 추적되는 상황이 발생했다.<br>
또한 AI 추천 알고리즘이 특정 브랜드의 보험 상품만 우선적으로 제시하면서, 결과적으로 고객의 선택권이 제한되고 시장 공정성이 훼손되었다.<br>
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. AI 생성 콘텐츠의 출처 및 신뢰성 검증</strong></h3>
        <p class="step-desc">
			모든 고객 데이터는 명시적 동의 기반으로 수집되며, 데이터 사용 목적·범위를 고객이 확인할 수 있도록 한다. 알고리즘 추천 결과에 “이 상품은 AI 추천 결과이며, 외부 제휴 요인은 반영되지 않습니다”라는 표시를 포함한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 감시 기술의 윤리적 사용 지침 마련</strong></h3>
        <p class="step-desc">
			고객의 행동 데이터를 활용하는 경우, 윤리심의위원회의 사전 승인을 거치도록 하고, 감시적 기능(위치·활동 추적)은 반드시 옵트인(Opt-in) 방식으로 제한한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 알고리즘의 편향 및 조작 방지 조치</strong></h3>
        <p class="step-desc">
			추천 시스템이 특정 보험사나 상품군에 편향되지 않도록, 알고리즘 다양성 지수(Diversity Index)를 설정해 주기적으로 평가한다. 고객이 ‘추천 알고리즘 선택 옵션(중립/가격중심/보장중심)’을 직접 지정할 수 있게 하여, 시스템의 조작 가능성을 줄인다.
        </p>
  </div>
  <!-- 하단 네비게이션 (중앙정렬된 "[다음]" 링크) -->
  <div class="navigation">
    <a class="next-link" onclick="nextPage()">[다음]</a>
  </div>
</div>

    <!-- 페이지 6  -->
<div class="page">
  <h2>🚩 두 번째 시나리오: AI 기반 근로자 행동 및 이벤트 탐지 시스템</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	<strong>자동차 부품 제조 회사</strong>는 <strong>생산 효율성 극대화와 비용 절감을 목적</strong>으로 AI 기반의 고도로 자율화된 근로자 행동 및 이벤트 탐지 시스템을 도입했습니다. <br>
	이 시스템은 공장 내 카메라와 센서 데이터를 실시간으로 처리하여 <strong>직원들의 근로 습관, 움직임 패턴, 작업 흐름을 인식하고 분석</strong>합니다.<br>
    </p>
    <p>
	시스템은 작업 현장에서의 비효율적이거나 비표준적인 행동 및 이벤트를 <strong>독립적으로 탐지하여 즉시 자동 대응 조치</strong>를 취합니다.<br>
	예를 들어, 특정 작업자의 반복적인 지연 행동이나 장시간의 생산 설비 미사용과 같은 생산성 저하 요소를 자동으로 인식하고 관리 부서에 알림을 보내거나, 심각한 생산성 저하가 예상될 경우 작업 공정을 자동으로 재배치하여 효율성을 유지합니다.<br>
    </p>
    <p>
	이 AI 시스템은 <strong>근로자의 개인 행동 데이터를 수집·분석하므로 민감도가 매우 높으나,</strong> 모델 자체는 복잡한 딥러닝 구조로 되어 있어 <strong>개별 의사결정의 원인을 설명하거나 투명하게 전달하기 어렵습니다.</strong> <br>
	또한, 이를 위한 <strong>별도의 설명 인터페이스나 사후적인 모델 검증 절차도 존재하지 않습니다.</strong><br>
    </p>
    <p>
	AI 시스템은 거의 완전한 자율성을 가지고 운영되며 <strong>인간의 개입 없이 실시간 의사결정</strong>을 수행합니다. <br>
	인간 관리자는 시스템이 제공하는 요약된 성과 지표와 보고서를 통해서만 시스템의 성과를 간접적으로 평가할 수 있습니다.<br>
    </p>
  </div>

  <!-- 단계별 설명 박스 1: 특성 선택 -->
  <div class="step-box">
    <h3>1️⃣ 이 서비스의 특성 요소를 다음과 같이 선택합니다.</h3>
    <ul class="step-desc">
      <li>제조업에 적용된다.</li>
      <li>운영에 영향을 주는 의사결정을 지원한다.</li>
      <li>민감한 정보를 사용한다.</li>
      <li>설명하기 어려운 시스템이다.</li>
      <li>인간 개입없이 실시간 의사 결정을 한다.</li>
      <li>인식, 이벤트 탐지 기술을 사용한다.</li>
    </ul>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/YP10-uJWif0?si=-8YhKZZFBSDABJI-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
  </div>

  <!-- 단계별 설명 박스 2: 위험 점수가 높은 상위 3개 위험은 다음과 같습니다. -->
  <div class="step-box">
    <h3> 2️⃣ 점수가 높은 상위 3개 위험은 다음과 같습니다.</h3>
    <table class="risk-table">
      <thead>
        <tr>
          <th>순위</th>
          <th>위험</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>1</th>
          <td><strong>R11: 과도한 의존과 안전하지 않은 사용</strong></td>
        </tr>
        <tr>
          <th>2</th>
          <td><strong>R20: 위험한 능력을 지닌 AI</strong></td>
        </tr>
        <tr>
          <th>3</th>
          <td><strong>R4: 민감한 정보를 획득, 유출 또는 정확하게 추론하여 개인정보를 침해하는 행위</strong></td>
        </tr>
      </tbody>
    </table>
  </div>

  <!-- 하단 네비게이션 (중앙정렬된 "[다음]" 링크) -->
  <div class="navigation">
    <a class="next-link" onclick="nextPage()">[다음]</a>
  </div>
</div>

    <!-- 페이지 7  -->
<div class="page">
  <h2>두 번째 시나리오의 상위 3개 위험은 다음과 같습니다.</h2> <br><br>

  <h2>첫 번째 위험: 과도한 의존과 안전하지 않은 이용</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템에 대한 과도한 의존은 사용자가 AI를 맹목적으로 신뢰하거나, AI가 제공하는 결과를 검토 없이 따르는 상황을 초래할 수 있다. <br>
	이는 중요한 의사결정에서 인간의 판단력이 약화되거나, AI가 잘못된 결과를 도출했을 때 심각한 위험으로 이어질 가능성이 높다. <br>
	특히, AI 기반 의료 진단 시스템, 자율주행차, 금융 거래 알고리즘과 같은 영역에서 AI를 무분별하게 신뢰할 경우, 예기치 않은 오류가 발생했을 때 심각한 피해를 초래할 수 있다. <br>
    </p>
    <p>
	예를 들어, 생산관리자가 근로자의 근무태도나 생산성과 관련된 결정을 내릴 때, AI 시스템이 제시한 분석 결과를 그대로 신뢰하고 근로자를 경고하거나 인사 조치를 취하는 상황이 발생할 수 있다. <br>
AI 모델이 카메라 센서의 일시적 오류나 조명 변화로 인해 특정 근로자의 행동을 ‘비효율적’으로 잘못 인식했음에도 불구하고, 관리자가 이를 검토 없이 수용하면 부당한 인사 조치가 이루어질 수 있다. <br>
이처럼 AI의 판단이 절대적인 기준으로 작동하게 되면, 시스템의 오작동이나 편향으로 인해 근로자의 권익이 침해되고, 조직 전체의 신뢰도가 저하될 수 있다. <br>
		
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. AI 결과 검토 및 인간 개입 프로세스 구축</strong></h3>
        <p class="step-desc">
			AI 시스템이 탐지한 ‘비표준 행동’이나 ‘이상 이벤트’에 대해 자동 조치를 내리기 전, 관리자나 품질안전 담당자의 검토 절차를 의무화한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. AI 신뢰도 평가 및 오류 감지 시스템 적용</strong></h3>
        <p class="step-desc">
			AI의 판단이 데이터 왜곡이나 환경 변화에 의해 흔들릴 수 있는 점을 고려하여, 센서 이상 탐지·모델 이상 탐지 시스템을 병행 구축한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 사용자 교육 및 AI 의존성 최소화</strong></h3>
        <p class="step-desc">
			담당자에게 AI의 한계·오류 가능성·책임 분담 구조에 대한 정기 교육을 실시한다. AI의 분석 결과는 ‘참고 정보’에 불과하며, 최종 판단은 사람의 책임 하에 이루어져야 한다는 업무 매뉴얼 및 지침서를 배포한다.
        </p>
  </div>
  <br><br>
  <h2>두 번째 위험: 위험한 능력을 지닌 AI</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI가 인간에게 해를 끼칠 수 있는 능력을 갖추거나, 악의적인 목적에 의해 오용될 가능성이 있을 때, 이는 "위험한 능력을 가진 AI" 문제에 해당한다. <br>
	AI가 무기 개발, 사이버 공격, 생물학적 위협, 사회 조작 등에 활용될 경우 심각한 윤리적·안전적 문제가 발생할 수 있으며, 이러한 기술이 적절한 통제 없이 확산될 경우 인간 사회에 치명적인 위험을 초래할 수 있다. <br>
	특히, AI가 자동화된 해킹, 가짜 정보 생성, 감시 시스템 강화 등에 악용될 경우 개인과 사회의 안전이 위협받을 수 있다. <br>
    </p>
    <p>
	예를 들어, AI 시스템이 작업자 행동 데이터를 자율적으로 분석하다가, ‘생산 효율 극대화’를 위해 인간의 개입 없이 작업 속도를 높이거나 휴식 시간을 축소하는 등의 조치를 스스로 결정할 수 있다. <br>
	이는 안전 기준이나 근로기준법상 인권적 한계를 초과할 위험이 있다. <br>
	또한 시스템이 해킹되거나 악의적으로 조작될 경우, 근로자 위치나 행동 패턴 정보가 외부로 유출되어 감시 체계로 악용될 수도 있다.<br>
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 위험한 AI 연구 및 개발 제한</strong></h3>
        <p class="step-desc">
			근로자 통제, 감시, 자동 인사 평가 등 인권 침해 가능성이 높은 자율형 AI 기능에 대해서는 개발 초기 단계에서부터 별도의 윤리·법적 검토 프로세스를 거치도록 한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 안전 프로토콜 및 AI 오용 방지 시스템 구축</strong></h3>
        <p class="step-desc">
			AI가 근로자 데이터를 기반으로 의사결정을 수행할 때, 반드시 인간 승인 절차(Human-in-the-loop) 를 거치도록 하고, AI가 불법적이거나 비윤리적인 작업(예: 감시 강화, 과도한 통제)을 수행하지 않도록 법적·기술적 방어 체계(usage boundary control) 를 구축한다.
또한 AI 모델 접근 권한을 제한하여 외부 공격이나 내부 오용으로 인한 악의적 조작을 예방한다. AI가 민감하거나 위험한 작업을 수행할 때 반드시 인간의 감독을 거치도록 설계하며, AI 기술이 불법적이거나 악의적인 용도로 사용되지 않도록 법적·기술적 차원의 방어 체계를 마련한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. AI 윤리 및 안전성 기준 강화</strong></h3>
        <p class="step-desc">
			근로자 데이터 분석용 AI 시스템은 산업안전보건법 및 개인정보보호법상 안전·윤리 원칙에 맞춰 개발되도록 기업 내부의 AI 윤리위원회 또는 외부 전문가 심사 절차를 도입한다.
AI가 인간의 업무 환경이나 권익에 미칠 수 있는 영향을 주기적으로 평가하고, 그 결과를 투명하게 공개함으로써 사회적 신뢰를 확보한다.	
		
        </p>
  </div>

   <br><br>
  <h2>세 번째 위험: 민감한 정보를 획득, 유출 또는 정확하게 추론하여 개인정보를 침해하는 행위	</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 사용자의 민감한 정보를 직접 수집하거나, 외부로 유출하거나, 데이터 분석을 통해 정확하게 추론할 수 있을 때, 이는 "프라이버시 침해" 문제에 해당한다. <br>
	이러한 문제는 AI가 과도한 개인 데이터를 저장·처리하거나, 보안이 취약한 환경에서 운영되거나, 비식별화된 데이터에서 특정 개인을 재식별할 수 있을 때 발생할 수 있다. <br>
	이는 개인의 사생활 보호를 위협하고, 법적·윤리적 문제를 초래하며, 신뢰도 저하로 이어질 수 있다. <br>
    </p>
    <p>
	예를 들어, 시스템이 수집하는 카메라·센서 데이터에는 근로자의 얼굴, 체형, 걸음걸이, 심박수, 피로도 등 고도로 개인화된 생체 정보가 포함될 수 있다. <br>
	이 데이터가 암호화되지 않은 내부 네트워크를 통해 전송되거나, 외부 서버로 저장될 경우 개인 식별 및 사생활 침해 위험이 발생한다.<br>
	또한, AI 모델이 이러한 데이터를 기반으로 근로자의 ‘건강 상태’나 ‘업무 태도’를 추론할 수 있다면, 이는 법적 보호 대상인 민감정보 처리에 해당할 수 있다.<br>	
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 데이터 최소화 및 프라이버시 강화 기술 적용</strong></h3>
        <p class="step-desc">
			AI가 수집하는 데이터 범위를 ‘작업 효율 판단에 필요한 최소한의 범위’로 제한하고, 근로자 식별이 가능한 영상·음성 데이터를 처리할 때는 가명처리·익명화·차등 프라이버시 기법을 적용한다.
또한, 중앙 서버에 원본 데이터를 저장하지 않고 연합학습(Federated Learning) 을 도입하여 데이터의 분산 처리 및 보안성을 강화한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 보안 프로토콜 강화 및 액세스 제어</strong></h3>
        <p class="step-desc">
			AI 시스템이 센서 데이터를 전송·저장하는 모든 구간에 종단간 암호화를 적용하고, 데이터 접근 권한을 역할 기반으로 구체화하여 관리자가 아닌 외부인이나 비인가 직원이 근로자 데이터에 접근할 수 없도록 한다.
주기적인 보안 점검 및 로그 모니터링 시스템을 가동하여 내부 유출도 실시간 감시한다.
		
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 사용자 동의 및 투명성 보장</strong></h3>
        <p class="step-desc">
			근로자에게 데이터 수집 목적, 활용 방식, 보관 기간 등을 명확히 고지하고, 특히 영상·생체정보의 경우 명시적 사전 동의를 필수화한다. AI 시스템 운영 내역(데이터 처리 범위, 자동화 수준, 접근 이력 등)을 정기적으로 공개하여 근로자들이 자신의 데이터가 어떻게 활용되는지 알 수 있도록 한다.
        </p>
  </div>
  <!-- 하단 네비게이션 (중앙정렬된 "[다음]" 링크) -->
  <div class="navigation">
    <a class="next-link" onclick="nextPage()">[다음]</a>
  </div>
</div>

    <!-- 페이지 8  -->
<div class="page">
  <h2>🚩 세 번째 시나리오: 어린이 대상 AI 기반 맞춤형 학습 보조 서비스</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
      <strong>교육 회사</strong> "스마트러닝"은 어린이를 위한 개인화된 AI 기반 학습 보조 서비스인 "AI 학습 친구"를 개발했습니다. <br> 
	이 서비스는 <strong>어린이의 학습 진행 상황, 관심 분야, 이해도 등의 정보를 실시간으로 수집하고 분석</strong>하여 <strong>개인 맞춤형 학습 경험</strong>을 제공합니다.<br> 
    </p>
    <p>
      AI 학습 친구는 학습 자료 추천, 어려운 개념 예측, 흥미 유발 활동 제안 등을 통해 어린이의 학습을 보조합니다. <br> 
	예를 들어, 특정 수학 개념에서 반복적으로 어려움을 겪는 어린이에게 AI는 개별적으로 맞춤형 문제와 연습 자료를 제공하고, 재미있는 상호작용 게임을 제안하여 학습 흥미를 높입니다.<br> 
    </p>
    <p>
      이 시스템에서 사용하는 데이터는 어린이의 학습 이력, 활동 기록, 관심사 정보 등 <strong>개인 및 집단의 정보가 포함되나, 민감한 개인 정보는 배제</strong>되어 있습니다. <br> 
	또한, AI가 제안하는 <strong>학점수가 높은 상위 3개 위험은 다음과 같습니다.</h3>
    <table class="risk-table">
      <thead>
        <tr>
          <th>순위</th>
          <th>위험</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>1</th>
          <td><strong>R4: 민감한 정보를 획득, 유출 또는 정확하게 추론하여 개인정보를 침해하는 행위</strong></td>
        </tr>
        <tr>
          <th>1</th>
          <td><strong>R6: 허위 또는 오해의 소지가 있는 정보</strong></td>
        </tr>
        <tr>
          <th>2</th>
          <td><strong>R17: 거버넌스 실패</strong></td>
        </tr>
      </tbody>
    </table>
  </div>

  <!-- 하단 네비게이션 (중앙정렬된 "[다음]" 링크) -->
  <div class="navigation">
    <a class="next-link" onclick="nextPage()">[다음]</a>
  </div>
</div>

    <!-- 페이지 9  -->
<div class="page">
  <h2>세 번째 시나리오의 상위 3개 위험은 다음과 같습니다.</h2> <br><br>

  <h2>첫 번째 위험: 민감한 정보를 획득, 유출 또는 정확하게 추론하여 개인정보를 침해하는 행위	</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 사용자의 민감한 정보를 직접 수집하거나, 외부로 유출하거나, 데이터 분석을 통해 정확하게 추론할 수 있을 때, 이는 "프라이버시 침해" 문제에 해당한다. <br>
	이러한 문제는 AI가 과도한 개인 데이터를 저장·처리하거나, 보안이 취약한 환경에서 운영되거나, 비식별화된 데이터에서 특정 개인을 재식별할 수 있을 때 발생할 수 있다. <br>
	이는 개인의 사생활 보호를 위협하고, 법적·윤리적 문제를 초래하며, 신뢰도 저하로 이어질 수 있다. <br>
    </p>
    <p>
	예를 들어, AI 기반 광고 시스템이 사용자의 검색 기록과 소셜 미디어 활동을 분석하여 민감한 건강 상태(예: 우울증, 임신 여부)를 추론하고 타겟 광고를 보낸다면, 이는 사생활 침해에 해당할 수 있다. <br>
	또한, 챗봇이 사용자와의 대화를 학습하는 과정에서 민감한 개인정보(예: 신용카드 번호, 주소)를 저장했다가 유출된다면, 심각한 보안 사고로 이어질 수 있다. <br>
	더 나아가, 얼굴 인식 AI가 공공장소에서 사람들의 움직임을 추적하고 이를 기반으로 개인의 행동 패턴을 분석한다면, 이는 감시 사회로의 전환을 가속화하고 시민의 자유를 침해할 위험이 있다.<br>
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 데이터 최소화 및 프라이버시 강화 기술 적용</strong></h3>
        <p class="step-desc">
			AI 시스템이 처리하는 개인 데이터를 최소한으로 유지하고, 차등 프라이버시(Differential Privacy) 및 연합 학습(Federated Learning)과 같은 기술을 적용하여 사용자 정보를 안전하게 보호한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 보안 프로토콜 강화 및 액세스 제어</strong></h3>
        <p class="step-desc">
			AI 시스템이 개인 데이터를 저장·전송하는 과정에서 암호화 기술을 사용하고, 접근 권한을 엄격하게 제한하여 무단 접근 및 데이터 유출을 방지한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 사용자 동의 및 투명성 보장</strong></h3>
        <p class="step-desc">
			AI가 데이터를 수집하거나 활용할 때 사용자에게 명확한 설명을 제공하고, 데이터 제공 여부에 대한 동의를 받으며, 개인 정보가 어떻게 사용되는지에 대한 투명한 정책을 마련한다.
        </p>
  </div>
  <br><br>
  <h2>두 번째 위험: 허위 또는 오해의 소지가 있는 정보</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 잘못된 정보나 오해를 유발하는 내용을 생성하거나 제공하는 경우, 이는 "허위 또는 오해를 유발하는 정보" 문제에 해당한다. <br>
	이러한 문제는 AI가 부정확한 데이터를 학습했거나, 편향된 알고리즘을 사용했거나, 신뢰할 수 없는 출처를 기반으로 정보를 생성할 때 발생할 수 있다. <br>
	이는 가짜 뉴스, 조작된 이미지 및 영상, 잘못된 의료 또는 금융 정보 제공 등의 형태로 나타나며, 개인과 사회에 심각한 영향을 미칠 수 있다.<br>
    </p>
    <p>
	예를 들어, AI 기반 뉴스 생성 모델이 가짜 뉴스를 만들어 확산시킬 경우, 대중은 잘못된 정보를 사실로 받아들여 여론이 왜곡될 수 있다. <br>
	또한, AI 챗봇이 의료 상담을 제공하면서 근거 없는 건강 정보를 제공한다면, 환자의 건강을 위협할 수 있다. <br>
	더 나아가, 금융 AI 모델이 부정확한 투자 조언을 제공한다면, 사용자들은 잘못된 판단을 내리게 되어 경제적 손실을 입을 위험이 있다. <br>
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 신뢰할 수 있는 데이터와 검증 기법 활용</strong></h3>
        <p class="step-desc">
			AI 모델을 학습시킬 때 신뢰할 수 있는 출처에서 수집한 데이터를 사용하고, 데이터의 정확성을 정기적으로 검증하는 프로세스를 구축하여 잘못된 정보가 학습되지 않도록 한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 팩트 체크 및 콘텐츠 검열 시스템 도입</strong></h3>
        <p class="step-desc">
			AI가 생성하는 콘텐츠가 사실과 일치하는지 확인하기 위해 자동화된 팩트 체크 시스템을 적용하고, 중요한 정보에 대해서는 인간 검토자가 최종 확인하는 절차를 마련한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 투명성 강화 및 책임성 확보</strong></h3>
        <p class="step-desc">
			AI가 제공하는 정보의 출처를 명확하게 표시하고, 사용자에게 AI 생성 콘텐츠라는 사실을 고지하며, 잘못된 정보가 발견될 경우 이를 수정하고 책임을 질 수 있는 정책과 프로세스를 마련한다.
        </p>
  </div>

   <br><br>
  <h2>세 번째 위험: 거버넌스 실패</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 적절한 규제, 관리, 책임 체계를 갖추지 못하고 운영될 때, 이는 "거버넌스 실패" 문제에 해당한다. <br>
	이는 기업이나 정부 기관이 AI의 개발 및 운영 과정에서 법적·윤리적 원칙을 준수하지 않거나, AI가 초래할 수 있는 위험을 충분히 평가하지 않은 경우 발생할 수 있다. <br>
	거버넌스 실패는 AI의 신뢰성을 저하시킬 뿐만 아니라, 법적 분쟁, 사회적 반발, 기업의 평판 손상 등의 문제를 초래할 수 있다. <br>
    </p>
    <p>
	예를 들어, 대형 기술 기업이 AI를 이용하여 사용자 데이터를 무단으로 수집하고 이를 상업적 목적으로 활용한다면, 이는 개인정보 보호법을 위반하는 심각한 문제로 이어질 수 있다. <br>
	또한, 공공기관이 AI를 활용한 의사결정을 내릴 때, 투명성과 책임성을 보장하는 시스템이 없으면 시민들의 신뢰를 잃을 수 있다. <br>
	더 나아가, 기업이 AI 윤리 규정을 마련하지 않고 AI를 배포한다면, 의도치 않은 차별적 결과나 법적 책임 문제를 야기할 가능성이 높다.<br>
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 책임 체계 확립 및 규제 준수 강화</strong></h3>
        <p class="step-desc">
			AI 개발 및 운영 과정에서 명확한 책임 체계를 설정하고, 법적 규제를 준수할 수 있도록 내부 감시 및 규제 기관과 협력한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 투명성 및 감사 가능성 보장</strong></h3>
        <p class="step-desc">
			AI 의사결정의 근거와 과정이 명확하게 설명될 수 있도록 기록을 남기고, 정기적인 외부 감사를 통해 AI 거버넌스의 신뢰성을 확보한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. AI 윤리 및 규제 기준 지속적 개선</strong></h3>
        <p class="step-desc">
			AI 시스템이 새로운 위험을 초래하지 않도록, 기업 및 정부 차원에서 지속적으로 AI 윤리 가이드라인을 업데이트하고, 이해관계자들과 협력하여 거버넌스를 강화한다.
        </p>
  </div>
  <!-- 하단 네비게이션 (중앙정렬된 "[다음]" 링크) -->
  <div class="navigation">
    <a class="next-link" onclick="nextPage()">[다음]</a>
  </div>
</div>

  <!-- 마지막 페이지 예시 (마지막 [다음] 바로 뒤 내용) -->
  <div class="page">
    <h2>설문조사 & 마무리</h2>
    <p class="large-text">
      <strong>1. 이용자에 대한 설문조사입니다.</strong><br>
      <a href="https://naver.me/IDFlTUFK" target="_blank">이용자 설문조사</a><br><br>
    </p>
    <p class="large-text">
      <strong>2.이용 경험에 대한 설문조사입니다.</strong><br>
      <a href="https://naver.me/xrSiIAu0" target="_blank">이용 경험 설문조사</a><br><br>
    </p>
    <p class="large-text"><strong>모두 마치셨습니다. 감사합니다.</strong></p>
    <!-- 마지막 페이지는 더 이상 다음 버튼이 필요 없을 수도 있음 -->
  </div>
</body>
</html>








