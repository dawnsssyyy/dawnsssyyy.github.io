<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <title>AI Risk Framework (Paginated)</title>
  <style>
    body {
      font-family: 'Segoe UI', sans-serif;
      margin: 20px;
      background-color: #f9f9f9;
      color: #333;
      line-height: 1.6;
    }
    /* 페이지 하나하나를 구분 */
    /* 페이지 기본 스타일 */
.page {
  display: none; /* 기본적으로 숨김 */
  margin: 20px 0;
}

/* 페이지 내 제목 색상 */
.page h1,
.page h2,
.page h3 {
  color: #4CAF50;
}

/* 내비게이션 스타일 (가운데 정렬) */
.navigation {
  text-align: center;
  margin-top: 30px;
}
.navigation a {
  font-size: 18px;
  color: #4CAF50;
  text-decoration: none;
  cursor: pointer;
}
.navigation a:hover {
  text-decoration: underline;
}

/* 연구 제목 */
.research-title {
  font-size: 25pt;    /* 크게 */
  font-weight: bold;
  margin-bottom: 20px;
}

/* 콘텐츠 박스 */
.content-box {
  border: 2px solid #4CAF50;
  background-color: #fff;
  padding: 20px;
  font-size: 18px;
  line-height: 1.8;
  border-radius: 8px;
  margin-bottom: 20px;
}

/* 강조 텍스트 */
.highlight {
  font-size: 20px;    /* 강조할 문장은 더 크고 굵게 */
  font-weight: bold;
  color: #000;
}

/* 소개 텍스트 */
.intro-text {
  font-size: 23px;
  margin-bottom: 20px;
}

/* 단계 목록 스타일 */
.steps-list {
  font-size: 18px;
  line-height: 1.8;
  padding-left: 20px;
  margin: 20px 0;
}

/* 단계별 설명 박스 (uniform style) */
.step-box {
  background-color: #f2f2f2;
  border: 1px solid #ddd;
  border-radius: 8px;
  padding: 15px;
  margin-bottom: 20px;
}

/* 각 단계 제목 */
.step-title {
  font-size: 22px;
  font-weight: bold;
  margin-bottom: 10px;
  color: #333;
}

/* 단계 설명 */
.step-desc {
  font-size: 18px;
  color: #555;
}

/* 위험 테이블 스타일 */
.risk-table {
  width: 100%;
  border-collapse: collapse;
  margin-top: 10px;
}
.risk-table th,
.risk-table td {
  border: 1px solid #ddd;
  padding: 10px;
  font-size: 18px;
}
.risk-table th {
  background-color: #4CAF50;
  color: #fff;
  font-size: 20px;
}

/* 시나리오 설명 박스 */
.scenario-box {
  background-color: #fff;
  border: 2px solid #4CAF50;
  border-radius: 8px;
  padding: 20px;
  font-size: 18px;
  line-height: 1.8;
  margin-bottom: 20px;
}

/* 다음 링크 스타일 */
.next-link {
  font-size: 18px;
  color: #4CAF50;
  text-decoration: none;
  cursor: pointer;
}
.next-link:hover {
  text-decoration: underline;
}
.large-text {
  font-size: 1.25rem;    /* 예: 기본보다 25% 크게 */
  line-height: 1.6;      /* 읽기 편한 줄 간격 */
  margin-bottom: 1em;
}
.video-container {
  position: relative;
  width: 90%;
  max-width: 700px;      /* 원하시는 최대 너비로 조절 */
  padding-bottom: 56.25%; /* 16:9 비율 유지 */
  height: 0;
  overflow: hidden;
  margin: 20px auto;     /* 위·아래 여백 20px, 중앙 정렬 */
}

.video-container iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;           /* 컨테이너 너비에 맞춤 */
  height: 100%;          /* 높이 자동 조절 */
}

</style>

  <script>
    let currentPage = 0;

    // 특정 페이지(index)만 보이게 하고, 나머지는 숨김
    function showPage(pageIndex) {
      const pages = document.getElementsByClassName('page');
      for (let i = 0; i < pages.length; i++) {
        pages[i].style.display = 'none';
      }
      if (pages[pageIndex]) {
        pages[pageIndex].style.display = 'block';
        currentPage = pageIndex;
      }
    }
    // "[다음]" 버튼 클릭 시 다음 페이지로 이동
    function nextPage() {
      const pages = document.getElementsByClassName('page');
      if (currentPage < pages.length - 1) {
        showPage(currentPage + 1);
      }
    }

    window.onload = function() {
      // 페이지가 로드되면 첫 번째 페이지부터 보여줌
      showPage(0);
    }
  </script>
</head>
<body>
  <!-- 
    예시로, PDF에 등장하는 '[다음]' 문구를 기준으로
    여러 <div class="page">로 나누었습니다.
    실제로는 PDF 전체 텍스트를 필요한 만큼 잘라 넣으시면 됩니다.
  -->

<!-- 페이지 1 (PDF의 첫 부분부터 첫 [다음] 전까지) -->
<div class="page">
  <h2>AI Risk Framework 이용자 설문조사</h2>
  
  <!-- 본 연구 목적 제목: 더 크게, 굵게 -->
  <h2>본 연구 목적11</h2>
 
  <!-- 본문 내용을 박스 형태로 감싸고, 글씨 크기 및 간격을 키움 -->
  <div class="content-box">
    <p>
      인공지능이 빠르게 발전하면서 그로 인한 위험도 증가하고 있습니다. 예를 들어, 인공지능은 허위 정보 생성, 개인정보 침해, 독성 콘텐츠 노출, 편향된 결과 등으로 다양한 위험을 유발합니다.<br><br>
      인공지능 제품/서비스를 개발할 때는 인공지능의 잠재적인 위험을 반드시 인식해야 합니다. 인공지능 위험을 인지하고 이를 최소화하기 위한 노력을 해야 사용자와 사회에 대한 피해를 줄일 수 있고, 제품/서비스 출시 이후에도 책임있는 관리와 신속한 문제 해결이 가능합니다. 그렇지 않을 경우 여러 법적 책임을 지게 되거나 제품/서비스 출시가 중단될 수 있습니다.<br><br>
      하지만 각 인공지능 제품/서비스가 유발하는 위험은 무엇인지, 그 중 중요한 위험인지 파악하는 것은 쉽지 않습니다. 인공지능이 유발하는 위험의 종류가 많고 다양하여, 인공지능 제품/서비스 준비 과정에서 모든 위험을 한꺼번에 다루기는 쉽지 않습니다.<br><br>
      따라서 인공지능 제품/서비스 특성에 따라 가장 심각하고 즉각적인 영향을 미칠 수 있는 위험부터 관리할 수 있도록 제시해주는 프레임워크가 필요합니다. 이에 우리는 제품/서비스 특성에 따라 인공지능 위험의 우선순위를 정해 보여주는 AI Risk Framework를 개발하였습니다.<br><br>
      <span class="highlight">본 프레임워크는 ‘기사’를 활용하여 ‘제품/서비스별 AI 위험’의 발생 빈도와 위해성을 측정하여 만들고, 제품/서비스 특성을 선택하면 위험을 ‘우선순위별’로 볼 수 있도록 제공합니다.</span><br><br>
      최근 기사를 기반으로 인공지능 제품/서비스 특성에 따라 위험이 발생한 빈도와 위해성을 수치화하고, 이를 기반으로 순위를 도출함으로써 실무자가 효과적이고 직관적으로 위험을 식별하고 관리할 수 있도록 돕습니다.
    </p>
  </div>
  
  <!-- 하단 네비게이션: 가운데 정렬, 단순 "[다음]" 텍스트 링크 -->
  <div class="navigation">
    <a class="next-link" onclick="nextPage()">[다음]</a>
  </div>
</div>


  <!-- 페이지 2 (두 번째 [다음] 전까지) -->
  <div class="page">
    <h2>🚩 AI Risk Framework 구축</h2>
    <p class="intro-text">우리의 AI Risk Framework는 다음과 같이 구축되었습니다.</p>

    <ul class="steps-list">
      <li class="step-box">
        <h3 class="step-title">1) 제품 및 서비스를 7개 특성으로 유형화</h3>
        <p class="step-desc">
          특성: (1) 적용 분야, (2) 의사결정 지원의 중요도, (3) 데이터 민감도, (4) 시스템의 설명가능성, (5) 의사결정 자동화 수준, (6) 사용대상, (7) 기술적 특징
        </p>
      </li>
      <li class="step-box">
        <h3 class="step-title">2) 기사 분석 및 위험 측정</h3>
        <p class="step-desc">
          일정 기간 동안 인공지능 위험 관련 기사를 크롤링한 후, 해당 기사 내용을 바탕으로 제품/서비스 특성과 위험 요소 간의 동시 등장 빈도(likelihood)와 피해 정도(Severity)를 정량적으로 계산합니다. <br>
	  이는 bottom-up 방식으로, 일반인이 인지하는 위험에 근거합니다.
        </p>
      </li>
      <li class="step-box">
        <h3 class="step-title">3) AI Risk Framework Table 완성</h3>
        <p class="step-desc">
          이 테이블에서 각 위험 요소와 제품/서비스 특성 사이의 수치는 ‘위험의 정도’를 나타냅니다.<br>
            예: 기술적으로 ‘D29 인식’ 특징이 있을 때, ‘부당한 차별과 허위진술 위험(R1)’은 2 정도 있습니다. <br>
          위험 요소 합산 값이 클수록 해당 위험은 더 중요하게 고려되어야 합니다.
        </p>
	<div class="image-container">
      <img
        src="image.png"
        alt="AI Risk Framework Table 예시"
        style="max-width: 100%; height: auto; display: block; margin: 20px auto;"
      />
    </div>
      </li>
      <li class="step-box">
        <h3 class="step-title">4) AI Risk Framework Table 활용</h3>
        <p class="step-desc">
          제품/서비스의 특성을 선택하면, 위험 요소별 합산값을 통해 중요한 AI 위험을 파악할 수 있습니다. (같은 행에서 합산 값이 클수록 더 중요한 위험으로 간주됩니다.)
        </p>
      </li>
    </ul>

    <div class="navigation">
      <a class="next-link" onclick="nextPage()">[다음]</a>
    </div>
  </div>

  <!-- 페이지 3 (세 번째 [다음] 전까지) -->
  <div class="page">
    <h2>실험에 대한 설명</h2>

   <p class="large-text">
    <strong>세 개의 AI 제품/서비스 시나리오</strong>에 대해서<br><br>
    <strong>(1) AI Risk Framework를 이용해 위험요소를 찾아보고</strong><br><br>
    <strong>(2) 상위 위험요소 3개에 대해서 추가적인 설명을 제공합니다.</strong><br><br>
    이제 본격적으로 시나리오를 보여드리겠습니다.
  </p>
    <!-- ...이후 내용... -->
    <div class="navigation">
      <a onclick="nextPage()">[다음]</a>
    </div>
  </div>

    <!-- 페이지 4  -->
<div class="page">
  <h2>🚩 첫 번째 시나리오: 개인 맞춤형 보험 상품 추천 및 리스크 관리 시스템</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
      <strong>금융 및 보험회사</strong> "스마트보험"은 AI 기반의 개인 맞춤형 보험 추천 및 리스크 관리 시스템을 구축했습니다. <br>
     이 시스템은 고객의 재정 상태, 생활 습관, 건강 정보와 같이 민감하고 개인적인 데이터를 바탕으로 보험 가입 여부 및 가입 조건을 추천합니다. <br>
    </p>
    <p>
      AI는 머신러닝과 지식구조를 활용하여 고객별로 미래의 리스크를 정확하게 예측하며, 고객에게 가장 적합한 보험상품을 제안합니다. <br>
     시스템은 고객의 <strong>건강 상태, 재정 상황, 직업군 등의 민감한 정보를 종합적으로 분석</strong>하여 <strong>생명, 안전, 기본권 등 중요한 인간 권리에 영향을 줄 수 있는 핵심 의사결정을 지원</strong>합니다.
    </p>
    <p>
      이러한 AI 시스템은 <strong>설명 가능한 인터페이스를 제공</strong>하여 고객 및 감독 기관이 의사결정 이유와 과정을 이해할 수 있도록 돕습니다. 모델이 복잡하더라도 별도의 설명 인터페이스와 사후 분석을 통해 공정성과 투명성을 검증합니다.
    </p>
    <p>
      또한, AI 시스템은 높은 자동화 수준으로 운영되지만, <strong>사람은 의사결정을 모니터링하며 필요시 즉각 개입하는 중간 자율도</strong>를 유지하여, 과도한 불리한 조건이 제시될 경우 공정성을 보장합니다.
    </p>
  </div>

  <!-- 단계별 설명 박스 1: 특성 선택 -->
  <div class="step-box">
    <h3>1️⃣ 위 시스템의 특성을 선택합니다.</h3>
    <ul class="step-desc">
      <li>금융·보험업에 적용된다.</li>
      <li>핵심적 의사결정을 지원한다.</li>
      <li>민감한 정보를 사용한다.</li>
      <li>설명 인터페이스를 포함한다.</li>
      <li>인간이 모니터링하며 필요시 개입한다.</li>
      <li>개인화, 예측, 지식구조를 위한 추론 기술을 사용한다.</li>
    </ul>
    <div class="video-container">
    <iframe
      src="https://drive.google.com/file/d/1T7FJHiUZW9e8AXS4fOq2Q9cxw5lnFjBc/preview"
      frameborder="0"
      allow="autoplay; encrypted-media"
      allowfullscreen>
     </iframe>
     </div>
  </div>

  <!-- 단계별 설명 박스 2: 위험 점수가 높은 상위 3개 위험은 다음과 같습니다. -->
  <div class="step-box">
    <h3>2️⃣ 위험 접수가 높은 상위 3개 위험은 다음과 같습니다.</h3>
    <table class="risk-table">
      <thead>
        <tr>
          <th>순위</th>
          <th>위험</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>1</th>
          <td><strong>R22: 투명성이나 해석 가능성 부족</strong></td>
        </tr>
        <tr>
          <th>2</th>
          <td><strong>R6: 허위 또는 오해의 소지가 있는 정보</strong></td>
        </tr>
        <tr>
          <th>2</th>
          <td><strong>R8: 허위 정보, 감시 및 대규모 영향력</strong></td>
        </tr>
      </tbody>
    </table>
  </div>
    <!-- ...이후 내용... -->
    <div class="navigation">
      <a onclick="nextPage()">[다음]</a>
    </div>
</div>


    <!-- 페이지 5  -->
<div class="page">
  <h2>첫 번째 시나리오의 상위 3개 위험은 다음과 같습니다.</h2> <br><br>

  <h2>첫 번째 위험: 투명성과 해석가능성 부족</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 인간에게 이해되지 않는 방식으로 작동할 때, 이를 "투명성 또는 해석 가능성 부족" 문제라고 한다. <br>
	이러한 문제는 AI가 의사결정을 내리는 과정이 불분명하거나 복잡하여 사용자, 개발자, 규제 당국 등이 그 판단 근거를 파악하기 어려운 상황에서 발생한다. <br>
	특히 딥러닝 기반 모델과 같이 복잡한 구조를 가진 AI 시스템은 "블랙박스"처럼 작동하여, 결과가 왜 도출되었는지 설명하기 어렵다. 이는 신뢰성 저하, 책임소재 불분명, 편향 감지의 어려움 등 다양한 위험을 초래할 수 있다. 
    </p>
    <p>
	예를 들어, 금융권에서 AI가 대출 신청을 거부했을 때, 고객과 은행 담당자가 그 이유를 알 수 없다면 공정성과 신뢰 문제가 발생할 수 있다. <br>
	또한, 자율주행 차량이 갑자기 방향을 바꿨을 때, 엔지니어가 그 의사결정의 이유를 분석할 수 없다면 안전성 평가와 개선이 어려워진다. <br>
	기업의 AI 기반 채용 시스템이 특정 지원자를 배제할 경우, 담당자가 그 이유를 해명할 수 없다면 차별 논란이 발생할 수 있으며, 이는 법적·윤리적 문제로 이어질 수 있다.
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 모델 해석 가능성 도구 활용</strong></h3>
        <p class="step-desc">
			SHAP(Shapley Additive Explanations) 또는 LIME(Local Interpretable Model-agnostic Explanations)과 같은 기법을 적용하여 AI의 의사결정 과정에서 어떤 요소가 중요한 영향을 미쳤는지 설명할 수 있도록 한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 투명성 문서화 및 보고 체계 구축</strong></h3>
        <p class="step-desc">
			AI 모델의 훈련 데이터, 알고리즘 구조, 한계점 등을 정리한 모델 카드(Model Card) 또는 데이터시트(Datasheets for Datasets)를 작성하여, AI 시스템이 어떤 방식으로 작동하는지 명확하게 공개한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 인간 감독 및 정기적인 감사 실시</strong></h3>
        <p class="step-desc">
			AI 의사결정 과정에서 전문가의 감독을 포함하고, 주기적인 감사(Audit)를 통해 편향, 공정성, 신뢰성을 평가하는 절차를 마련하여 AI의 투명성을 지속적으로 향상시킨다.
        </p>
  </div>
  <br><br>
  <h2>두 번째 위험: 투명성과 해석가능성 부족</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 잘못된 정보나 오해를 유발하는 내용을 생성하거나 제공하는 경우, 이는 "허위 또는 오해를 유발하는 정보" 문제에 해당한다. <br>
	이러한 문제는 AI가 부정확한 데이터를 학습했거나, 편향된 알고리즘을 사용했거나, 신뢰할 수 없는 출처를 기반으로 정보를 생성할 때 발생할 수 있다. <br>
	이는 가짜 뉴스, 조작된 이미지 및 영상, 잘못된 의료 또는 금융 정보 제공 등의 형태로 나타나며, 개인과 사회에 심각한 영향을 미칠 수 있다.<br>
    </p>
    <p>
	예를 들어, AI 기반 뉴스 생성 모델이 가짜 뉴스를 만들어 확산시킬 경우, 대중은 잘못된 정보를 사실로 받아들여 여론이 왜곡될 수 있다. <br>
	또한, AI 챗봇이 의료 상담을 제공하면서 근거 없는 건강 정보를 제공한다면, 환자의 건강을 위협할 수 있다. <br>
	더 나아가, 금융 AI 모델이 부정확한 투자 조언을 제공한다면, 사용자들은 잘못된 판단을 내리게 되어 경제적 손실을 입을 위험이 있다.<br>
	기업의 AI 기반 채용 시스템이 특정 지원자를 배제할 경우, 담당자가 그 이유를 해명할 수 없다면 차별 논란이 발생할 수 있으며, 이는 법적·윤리적 문제로 이어질 수 있다.
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 신뢰할 수 있는 데이터와 검증 기법 활용</strong></h3>
        <p class="step-desc">
			AI 모델을 학습시킬 때 신뢰할 수 있는 출처에서 수집한 데이터를 사용하고, 데이터의 정확성을 정기적으로 검증하는 프로세스를 구축하여 잘못된 정보가 학습되지 않도록 한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 팩트 체크 및 콘텐츠 검열 시스템 도입</strong></h3>
        <p class="step-desc">
			AI가 생성하는 콘텐츠가 사실과 일치하는지 확인하기 위해 자동화된 팩트 체크 시스템을 적용하고, 중요한 정보에 대해서는 인간 검토자가 최종 확인하는 절차를 마련한다.여, AI 시스템이 어떤 방식으로 작동하는지 명확하게 공개한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 투명성 강화 및 책임성 확보</strong></h3>
        <p class="step-desc">
			AI가 제공하는 정보의 출처를 명확하게 표시하고, 사용자에게 AI 생성 콘텐츠라는 사실을 고지하며, 잘못된 정보가 발견될 경우 이를 수정하고 책임을 질 수 있는 정책과 프로세스를 마련한다.
        </p>
  </div>

   <br><br>
  <h2>세 번째 위험: 허위 정보, 감시 및 대규모 영향력</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 허위 정보를 대량으로 생성하거나, 사람들의 행동을 감시하고 분석하며, 특정한 의견이나 결정을 조작하는 데 사용될 때, 이는 "허위 정보, 감시, 대규모 영향력 행사" 문제에 해당한다. <br>
	이러한 문제는 AI가 사회적 여론을 조작하는 데 악용되거나, 대규모 감시 시스템이 개인의 자유를 침해하거나, 특정 집단을 선동하거나 억압하는 데 활용될 때 발생한다. <br>
	이는 민주적 의사결정을 왜곡하고, 표현의 자유를 위협하며, 공정한 사회 구조를 해칠 위험이 있다. <br>
    </p>
    <p>
	예를 들어, AI 기반 가짜 뉴스 생성 기술이 선거 기간 동안 특정 후보에 대한 허위 정보를 대량 유포하여 여론을 조작한다면, 이는 민주주의의 근본을 위협하는 행위가 될 수 있다. <br>
	또한, 정부나 기업이 AI 감시 시스템을 활용하여 사람들의 온라인 활동과 실제 움직임을 추적하고 이를 바탕으로 행동을 통제한다면, 개인의 사생활이 심각하게 침해될 수 있다. <br>
	더 나아가, 알고리즘이 사용자 맞춤형 콘텐츠를 제공하는 과정에서 특정한 정치적·사회적 견해를 강조하여 사람들의 의견을 편향되게 만든다면, 이는 사회적 분열을 심화시킬 수 있다. <br>
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. AI 생성 콘텐츠의 출처 및 신뢰성 검증</strong></h3>
        <p class="step-desc">
			AI가 생산한 뉴스, 영상, 이미지 등에 워터마크 또는 메타데이터를 추가하여 원본 여부를 확인할 수 있도록 하고, 허위 정보 탐지 시스템을 도입하여 신뢰도를 높인다.정에서 어떤 요소가 중요한 영향을 미쳤는지 설명할 수 있도록 한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 감시 기술의 윤리적 사용 지침 마련</strong></h3>
        <p class="step-desc">
			AI 기반 감시 기술이 사용될 경우 명확한 법적·윤리적 기준을 설정하고, 시민의 권리를 보호하기 위한 독립적인 감독 기관을 운영하여 남용을 방지한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 알고리즘의 편향 및 조작 방지 조치</strong></h3>
        <p class="step-desc">
			추천 시스템이 사용자에게 특정한 견해를 강요하지 않도록 알고리즘의 다양성과 균형을 보장하고, AI가 제안하는 콘텐츠가 다양한 시각을 반영하도록 조정한다.
        </p>
  </div>
  <!-- 하단 네비게이션 (중앙정렬된 "[다음]" 링크) -->
  <div class="navigation">
    <a class="next-link" onclick="nextPage()">[다음]</a>
  </div>
</div>

    <!-- 페이지 6  -->
<div class="page">
  <h2>🚩 두 번째 시나리오: AI 기반 근로자 행동 및 이벤트 탐지 시스템</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	<strong>자동차 부품 제조 회사</strong>는 <strong>생산 효율성 극대화와 비용 절감을 목적</strong>으로 AI 기반의 고도로 자율화된 근로자 행동 및 이벤트 탐지 시스템을 도입했습니다. <br>
	이 시스템은 공장 내 카메라와 센서 데이터를 실시간으로 처리하여 <strong>직원들의 근로 습관, 움직임 패턴, 작업 흐름을 인식하고 분석</strong>합니다.<br>
    </p>
    <p>
	시스템은 작업 현장에서의 비효율적이거나 비표준적인 행동 및 이벤트를 <strong>독립적으로 탐지하여 즉시 자동 대응 조치</strong>를 취합니다.<br>
	예를 들어, 특정 작업자의 반복적인 지연 행동이나 장시간의 생산 설비 미사용과 같은 생산성 저하 요소를 자동으로 인식하고 관리 부서에 알림을 보내거나, 심각한 생산성 저하가 예상될 경우 작업 공정을 자동으로 재배치하여 효율성을 유지합니다.<br>
    </p>
    <p>
	이 AI 시스템은 <strong>근로자의 개인 행동 데이터를 수집·분석하므로 민감도가 매우 높으나,</strong> 모델 자체는 복잡한 딥러닝 구조로 되어 있어 <strong>개별 의사결정의 원인을 설명하거나 투명하게 전달하기 어렵습니다.</strong> <br>
	또한, 이를 위한 <strong>별도의 설명 인터페이스나 사후적인 모델 검증 절차도 존재하지 않습니다.</strong><br>
    </p>
    <p>
	AI 시스템은 거의 완전한 자율성을 가지고 운영되며 <strong>인간의 개입 없이 실시간 의사결정</strong>을 수행합니다. <br>
	인간 관리자는 시스템이 제공하는 요약된 성과 지표와 보고서를 통해서만 시스템의 성과를 간접적으로 평가할 수 있습니다.<br>
    </p>
  </div>

  <!-- 단계별 설명 박스 1: 특성 선택 -->
  <div class="step-box">
    <h3>1️⃣ 위 시스템의 특성을 선택합니다.</h3>
    <ul class="step-desc">
      <li>제조업에 적용된다.</li>
      <li>운영적 의사결정을 지원한다.</li>
      <li>민감한 정보를 사용한다.</li>
      <li>설명하기 어려운 시스템이다.</li>
      <li>인간 개입없이 실시간 의사 결정을 한다.</li>
      <li>인식, 이벤트 탐지 기술을 사용한다.</li>
    </ul>
  </div>

  <!-- 단계별 설명 박스 2: 위험 점수가 높은 상위 3개 위험은 다음과 같습니다. -->
  <div class="step-box">
    <h3> 2️⃣ 위험 접수가 높은 상위 3개 위험은 다음과 같습니다.</h3>
    <table class="risk-table">
      <thead>
        <tr>
          <th>순위</th>
          <th>위험</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>1</th>
          <td><strong>R11: 과도한 의존과 안전하지 않은 사용</strong></td>
        </tr>
        <tr>
          <th>2</th>
          <td><strong>R20: 위험한 능력을 지닌 AI</strong></td>
        </tr>
        <tr>
          <th>3</th>
          <td><strong>R4: 민감한 정보를 획득, 유출 또는 정확하게 추론하여 개인정보를 침해하는 행위</strong></td>
        </tr>
      </tbody>
    </table>
  </div>

  <!-- 하단 네비게이션 (중앙정렬된 "[다음]" 링크) -->
  <div class="navigation">
    <a class="next-link" onclick="nextPage()">[다음]</a>
  </div>
</div>

    <!-- 페이지 7  -->
<div class="page">
  <h2>두 번째 시나리오의 상위 3개 위험은 다음과 같습니다.</h2> <br><br>

  <h2>첫 번째 위험: 과도한 의존과 안전하지 않은 이용</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템에 대한 과도한 의존은 사용자가 AI를 맹목적으로 신뢰하거나, AI가 제공하는 결과를 검토 없이 따르는 상황을 초래할 수 있다. <br>
	이는 중요한 의사결정에서 인간의 판단력이 약화되거나, AI가 잘못된 결과를 도출했을 때 심각한 위험으로 이어질 가능성이 높다. <br>
	특히, AI 기반 의료 진단 시스템, 자율주행차, 금융 거래 알고리즘과 같은 영역에서 AI를 무분별하게 신뢰할 경우, 예기치 않은 오류가 발생했을 때 심각한 피해를 초래할 수 있다. <br>
    </p>
    <p>
	예를 들어, 의료 AI가 암 환자에게 잘못된 치료 방법을 추천했음에도 의사가 이를 확인하지 않고 그대로 따를 경우, 환자의 생명에 직접적인 위협이 될 수 있다. <br>
	또한, 자율주행 차량이 센서 오류로 인해 오작동했을 때, 운전자가 AI의 판단을 그대로 믿고 개입하지 않는다면 대형 사고로 이어질 위험이 크다. <br>
	더 나아가, 금융 거래 알고리즘이 변동성이 큰 시장에서 예상치 못한 결정을 내릴 경우, 이를 감시하는 인간의 개입 없이 그대로 실행된다면 대규모 경제적 손실이 발생할 수 있다.<br>
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. AI 결과 검토 및 인간 개입 프로세스 구축</strong></h3>
        <p class="step-desc">
			AI가 내린 결정을 최종적으로 검토할 수 있는 인간 전문가의 개입 절차를 마련하고, 중요한 의사결정에서 AI의 판단을 보조적 역할로 활용하도록 한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. AI 신뢰도 평가 및 오류 감지 시스템 적용</strong></h3>
        <p class="step-desc">
			AI 모델이 오작동하거나 예상치 못한 결과를 생성할 가능성을 분석하고, 실시간으로 오류를 감지하여 자동으로 경고를 보내는 시스템을 도입한다.으로 작동하는지 명확하게 공개한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 사용자 교육 및 AI 의존성 최소화</strong></h3>
        <p class="step-desc">
			AI 사용자(의사, 운전자, 금융 전문가 등)에게 AI의 한계와 오류 가능성을 인식하도록 교육하고, AI를 맹목적으로 신뢰하지 않도록 하는 가이드라인을 마련한다.
        </p>
  </div>
  <br><br>
  <h2>두 번째 위험: 위험한 능력을 지닌 AI</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI가 인간에게 해를 끼칠 수 있는 능력을 갖추거나, 악의적인 목적에 의해 오용될 가능성이 있을 때, 이는 "위험한 능력을 가진 AI" 문제에 해당한다. <br>
	AI가 무기 개발, 사이버 공격, 생물학적 위협, 사회 조작 등에 활용될 경우 심각한 윤리적·안전적 문제가 발생할 수 있으며, 이러한 기술이 적절한 통제 없이 확산될 경우 인간 사회에 치명적인 위험을 초래할 수 있다. <br>
	특히, AI가 자동화된 해킹, 가짜 정보 생성, 감시 시스템 강화 등에 악용될 경우 개인과 사회의 안전이 위협받을 수 있다. <br>
    </p>
    <p>
	예를 들어, AI 기반 해킹 시스템이 자동으로 사이버 공격을 수행하고 보안 시스템을 무력화한다면, 이는 국가 차원의 보안 위협으로 이어질 수 있다. <br>
	또한, AI가 대량 살상 무기 개발에 활용되거나, 군사적 의사결정을 자동화하는 데 사용될 경우, 예기치 않은 사상자를 초래하는 등 인간의 통제력을 벗어난 위험한 상황이 발생할 수 있다. <br>
	더 나아가, AI가 합성 생물학 기술과 결합되어 새로운 바이러스를 설계하는 데 사용된다면, 이는 공중 보건과 생명윤리에 심각한 도전 과제가 될 수 있다.
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 위험한 AI 연구 및 개발 제한</strong></h3>
        <p class="step-desc">
			특정한 위험한 AI 기술(예: 자율 무기, 공격적 사이버 AI)의 연구 및 개발을 엄격히 제한하고, 국제적 협력을 통해 AI 기술이 악용되지 않도록 감시 및 규제를 강화한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 안전 프로토콜 및 AI 오용 방지 시스템 구축</strong></h3>
        <p class="step-desc">
			AI가 민감하거나 위험한 작업을 수행할 때, 반드시 인간의 감독을 거치도록 설계하며, AI 기술이 불법적이거나 악의적인 용도로 사용되지 않도록 법적·기술적 차원의 방어 체계를 마련한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. AI 윤리 및 안전성 기준 강화</strong></h3>
        <p class="step-desc">
			AI가 사회에 미칠 수 있는 위험을 사전에 평가하고, 윤리적 가이드라인을 강화하며, AI 개발자와 기업이 책임 있는 AI 개발을 준수하도록 국제적 규범과 협약을 도입한다.
        </p>
  </div>

   <br><br>
  <h2>세 번째 위험: 민감한 정보를 획득, 유출 또는 정확하게 추론하여 개인정보를 침해하는 행위	</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 사용자의 민감한 정보를 직접 수집하거나, 외부로 유출하거나, 데이터 분석을 통해 정확하게 추론할 수 있을 때, 이는 "프라이버시 침해" 문제에 해당한다. <br>
	이러한 문제는 AI가 과도한 개인 데이터를 저장·처리하거나, 보안이 취약한 환경에서 운영되거나, 비식별화된 데이터에서 특정 개인을 재식별할 수 있을 때 발생할 수 있다. <br>
	이는 개인의 사생활 보호를 위협하고, 법적·윤리적 문제를 초래하며, 신뢰도 저하로 이어질 수 있다. <br>
    </p>
    <p>
	예를 들어, AI 기반 광고 시스템이 사용자의 검색 기록과 소셜 미디어 활동을 분석하여 민감한 건강 상태(예: 우울증, 임신 여부)를 추론하고 타겟 광고를 보낸다면, 이는 사생활 침해에 해당할 수 있다. <br>
	또한, 챗봇이 사용자와의 대화를 학습하는 과정에서 민감한 개인정보(예: 신용카드 번호, 주소)를 저장했다가 유출된다면, 심각한 보안 사고로 이어질 수 있다. <br>
	더 나아가, 얼굴 인식 AI가 공공장소에서 사람들의 움직임을 추적하고 이를 기반으로 개인의 행동 패턴을 분석한다면, 이는 감시 사회로의 전환을 가속화하고 시민의 자유를 침해할 위험이 있다. <br>
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 데이터 최소화 및 프라이버시 강화 기술 적용</strong></h3>
        <p class="step-desc">
			AI 시스템이 처리하는 개인 데이터를 최소한으로 유지하고, 차등 프라이버시(Differential Privacy) 및 연합 학습(Federated Learning)과 같은 기술을 적용하여 사용자 정보를 안전하게 보호한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 보안 프로토콜 강화 및 액세스 제어</strong></h3>
        <p class="step-desc">
			AI 시스템이 개인 데이터를 저장·전송하는 과정에서 암호화 기술을 사용하고, 접근 권한을 엄격하게 제한하여 무단 접근 및 데이터 유출을 방지한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 사용자 동의 및 투명성 보장</strong></h3>
        <p class="step-desc">
			AI가 데이터를 수집하거나 활용할 때 사용자에게 명확한 설명을 제공하고, 데이터 제공 여부에 대한 동의를 받으며, 개인 정보가 어떻게 사용되는지에 대한 투명한 정책을 마련한다.
        </p>
  </div>
  <!-- 하단 네비게이션 (중앙정렬된 "[다음]" 링크) -->
  <div class="navigation">
    <a class="next-link" onclick="nextPage()">[다음]</a>
  </div>
</div>

    <!-- 페이지 8  -->
<div class="page">
  <h2>🚩 세 번째 시나리오: 어린이 대상 AI 기반 맞춤형 학습 보조 서비스</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
      <strong>교육 회사</strong> "스마트러닝"은 어린이를 위한 개인화된 AI 기반 학습 보조 서비스인 "AI 학습 친구"를 개발했습니다. <br> 
	이 서비스는 <strong>어린이의 학습 진행 상황, 관심 분야, 이해도 등의 정보를 실시간으로 수집하고 분석</strong>하여 <strong>개인 맞춤형 학습 경험</strong>을 제공합니다.<br> 
    </p>
    <p>
      AI 학습 친구는 학습 자료 추천, 어려운 개념 예측, 흥미 유발 활동 제안 등을 통해 어린이의 학습을 보조합니다. <br> 
	예를 들어, 특정 수학 개념에서 반복적으로 어려움을 겪는 어린이에게 AI는 개별적으로 맞춤형 문제와 연습 자료를 제공하고, 재미있는 상호작용 게임을 제안하여 학습 흥미를 높입니다.<br> 
    </p>
    <p>
      이 시스템에서 사용하는 데이터는 어린이의 학습 이력, 활동 기록, 관심사 정보 등 <strong>개인 및 집단의 정보가 포함되나, 민감한 개인 정보는 배제</strong>되어 있습니다. <br> 
	또한, AI가 제안하는 <strong>학습 활동 및 추천의 이유와 근거는</strong> AI 모델 자체와 추가적인 설명 모듈을 통해 어린이 및 부모에게 <strong>투명하게 전달</strong>됩니다.<br> 
    </p>
    <p>
      AI 시스템은 <strong>낮은 수준의 자율성</strong>으로 설계되어 있습니다. <br> 
	최종적인 학습 결정 및 선택은 항상 어린이와 부모가 내리며, AI는 어디까지나 <strong>보조적이고 추천하는 역할</strong>에 머뭅니다. <br> 
    </p>
  </div>

  <!-- 단계별 설명 박스 1: 특성 선택 -->
  <div class="step-box">
    <h3>1️⃣ 위 시스템의 특성을 선택합니다.</h3>
    <ul class="step-desc">
      <li>교육·서비스업에 적용된다.</li>
      <li>일반적 의사결정을 지원한다.</li>
      <li>보통 정도 민감한 정보를 사용한다.</li>
      <li>설명 가능한 시스템이다.</li>
      <li>추천하는 보조적인 역할만 수행한다.</li>
      <li>어린이(제한능력자)가 사용한다.</li>
      <li>예측, 개인화, 상호작용 지원 기술을 사용한다.</li>
    </ul>
  </div>

  <!-- 단계별 설명 박스 2: 위험 점수가 높은 상위 3개 위험은 다음과 같습니다. -->
  <div class="step-box">
    <h3>2️⃣ 위험 접수가 높은 상위 3개 위험은 다음과 같습니다.</h3>
    <table class="risk-table">
      <thead>
        <tr>
          <th>순위</th>
          <th>위험</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>1</th>
          <td><strong>R4: 민감한 정보를 획득, 유출 또는 정확하게 추론하여 개인정보를 침해하는 행위</strong></td>
        </tr>
        <tr>
          <th>1</th>
          <td><strong>R6: 허위 또는 오해의 소지가 있는 정보</strong></td>
        </tr>
        <tr>
          <th>2</th>
          <td><strong>R17: 거버넌스 실패</strong></td>
        </tr>
      </tbody>
    </table>
  </div>

  <!-- 하단 네비게이션 (중앙정렬된 "[다음]" 링크) -->
  <div class="navigation">
    <a class="next-link" onclick="nextPage()">[다음]</a>
  </div>
</div>

    <!-- 페이지 9  -->
<div class="page">
  <h2>두 번째 시나리오의 상위 3개 위험은 다음과 같습니다.</h2> <br><br>

  <h2>첫 번째 위험: 민감한 정보를 획득, 유출 또는 정확하게 추론하여 개인정보를 침해하는 행위	</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 사용자의 민감한 정보를 직접 수집하거나, 외부로 유출하거나, 데이터 분석을 통해 정확하게 추론할 수 있을 때, 이는 "프라이버시 침해" 문제에 해당한다. <br>
	이러한 문제는 AI가 과도한 개인 데이터를 저장·처리하거나, 보안이 취약한 환경에서 운영되거나, 비식별화된 데이터에서 특정 개인을 재식별할 수 있을 때 발생할 수 있다. <br>
	이는 개인의 사생활 보호를 위협하고, 법적·윤리적 문제를 초래하며, 신뢰도 저하로 이어질 수 있다. <br>
    </p>
    <p>
	예를 들어, AI 기반 광고 시스템이 사용자의 검색 기록과 소셜 미디어 활동을 분석하여 민감한 건강 상태(예: 우울증, 임신 여부)를 추론하고 타겟 광고를 보낸다면, 이는 사생활 침해에 해당할 수 있다. <br>
	또한, 챗봇이 사용자와의 대화를 학습하는 과정에서 민감한 개인정보(예: 신용카드 번호, 주소)를 저장했다가 유출된다면, 심각한 보안 사고로 이어질 수 있다. <br>
	더 나아가, 얼굴 인식 AI가 공공장소에서 사람들의 움직임을 추적하고 이를 기반으로 개인의 행동 패턴을 분석한다면, 이는 감시 사회로의 전환을 가속화하고 시민의 자유를 침해할 위험이 있다.<br>
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 데이터 최소화 및 프라이버시 강화 기술 적용</strong></h3>
        <p class="step-desc">
			AI 시스템이 처리하는 개인 데이터를 최소한으로 유지하고, 차등 프라이버시(Differential Privacy) 및 연합 학습(Federated Learning)과 같은 기술을 적용하여 사용자 정보를 안전하게 보호한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 보안 프로토콜 강화 및 액세스 제어</strong></h3>
        <p class="step-desc">
			AI 시스템이 개인 데이터를 저장·전송하는 과정에서 암호화 기술을 사용하고, 접근 권한을 엄격하게 제한하여 무단 접근 및 데이터 유출을 방지한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 사용자 동의 및 투명성 보장</strong></h3>
        <p class="step-desc">
			AI가 데이터를 수집하거나 활용할 때 사용자에게 명확한 설명을 제공하고, 데이터 제공 여부에 대한 동의를 받으며, 개인 정보가 어떻게 사용되는지에 대한 투명한 정책을 마련한다.
        </p>
  </div>
  <br><br>
  <h2>두 번째 위험: 허위 또는 오해의 소지가 있는 정보</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 잘못된 정보나 오해를 유발하는 내용을 생성하거나 제공하는 경우, 이는 "허위 또는 오해를 유발하는 정보" 문제에 해당한다. <br>
	이러한 문제는 AI가 부정확한 데이터를 학습했거나, 편향된 알고리즘을 사용했거나, 신뢰할 수 없는 출처를 기반으로 정보를 생성할 때 발생할 수 있다. <br>
	이는 가짜 뉴스, 조작된 이미지 및 영상, 잘못된 의료 또는 금융 정보 제공 등의 형태로 나타나며, 개인과 사회에 심각한 영향을 미칠 수 있다.<br>
    </p>
    <p>
	예를 들어, AI 기반 뉴스 생성 모델이 가짜 뉴스를 만들어 확산시킬 경우, 대중은 잘못된 정보를 사실로 받아들여 여론이 왜곡될 수 있다. <br>
	또한, AI 챗봇이 의료 상담을 제공하면서 근거 없는 건강 정보를 제공한다면, 환자의 건강을 위협할 수 있다. <br>
	더 나아가, 금융 AI 모델이 부정확한 투자 조언을 제공한다면, 사용자들은 잘못된 판단을 내리게 되어 경제적 손실을 입을 위험이 있다. <br>
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 신뢰할 수 있는 데이터와 검증 기법 활용</strong></h3>
        <p class="step-desc">
			AI 모델을 학습시킬 때 신뢰할 수 있는 출처에서 수집한 데이터를 사용하고, 데이터의 정확성을 정기적으로 검증하는 프로세스를 구축하여 잘못된 정보가 학습되지 않도록 한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 팩트 체크 및 콘텐츠 검열 시스템 도입</strong></h3>
        <p class="step-desc">
			AI가 생성하는 콘텐츠가 사실과 일치하는지 확인하기 위해 자동화된 팩트 체크 시스템을 적용하고, 중요한 정보에 대해서는 인간 검토자가 최종 확인하는 절차를 마련한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. 투명성 강화 및 책임성 확보</strong></h3>
        <p class="step-desc">
			AI가 제공하는 정보의 출처를 명확하게 표시하고, 사용자에게 AI 생성 콘텐츠라는 사실을 고지하며, 잘못된 정보가 발견될 경우 이를 수정하고 책임을 질 수 있는 정책과 프로세스를 마련한다.
        </p>
  </div>

   <br><br>
  <h2>세 번째 위험: 거버넌스 실패</h2>
  
  <!-- 시나리오 설명 박스 -->
  <div class="scenario-box">
    <p>
	AI 시스템이 적절한 규제, 관리, 책임 체계를 갖추지 못하고 운영될 때, 이는 "거버넌스 실패" 문제에 해당한다. <br>
	이는 기업이나 정부 기관이 AI의 개발 및 운영 과정에서 법적·윤리적 원칙을 준수하지 않거나, AI가 초래할 수 있는 위험을 충분히 평가하지 않은 경우 발생할 수 있다. <br>
	거버넌스 실패는 AI의 신뢰성을 저하시킬 뿐만 아니라, 법적 분쟁, 사회적 반발, 기업의 평판 손상 등의 문제를 초래할 수 있다. <br>
    </p>
    <p>
	예를 들어, 대형 기술 기업이 AI를 이용하여 사용자 데이터를 무단으로 수집하고 이를 상업적 목적으로 활용한다면, 이는 개인정보 보호법을 위반하는 심각한 문제로 이어질 수 있다. <br>
	또한, 공공기관이 AI를 활용한 의사결정을 내릴 때, 투명성과 책임성을 보장하는 시스템이 없으면 시민들의 신뢰를 잃을 수 있다. <br>
	더 나아가, 기업이 AI 윤리 규정을 마련하지 않고 AI를 배포한다면, 의도치 않은 차별적 결과나 법적 책임 문제를 야기할 가능성이 높다.<br>
    </p>
  </div>

   <p class="large-text">
    <strong>대응 방안</strong>
  </p>

  <div class="step-box">
    <h3><strong>1. 책임 체계 확립 및 규제 준수 강화</strong></h3>
        <p class="step-desc">
			AI 개발 및 운영 과정에서 명확한 책임 체계를 설정하고, 법적 규제를 준수할 수 있도록 내부 감시 및 규제 기관과 협력한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>2. 투명성 및 감사 가능성 보장</strong></h3>
        <p class="step-desc">
			AI 의사결정의 근거와 과정이 명확하게 설명될 수 있도록 기록을 남기고, 정기적인 외부 감사를 통해 AI 거버넌스의 신뢰성을 확보한다.
        </p>
  </div>
  <div class="step-box">
    <h3><strong>3. AI 윤리 및 규제 기준 지속적 개선</strong></h3>
        <p class="step-desc">
			AI 시스템이 새로운 위험을 초래하지 않도록, 기업 및 정부 차원에서 지속적으로 AI 윤리 가이드라인을 업데이트하고, 이해관계자들과 협력하여 거버넌스를 강화한다.
        </p>
  </div>
  <!-- 하단 네비게이션 (중앙정렬된 "[다음]" 링크) -->
  <div class="navigation">
    <a class="next-link" onclick="nextPage()">[다음]</a>
  </div>
</div>

  <!-- 마지막 페이지 예시 (마지막 [다음] 바로 뒤 내용) -->
  <div class="page">
    <h2>설문조사 & 마무리</h2>
    <p class="large-text">
      <strong>1. 이용자에 대한 설문조사입니다.</strong><br>
      <a href="https://naver.me/IDFlTUFK" target="_blank">이용자 설문조사</a><br><br>
    </p>
    <p class="large-text">
      <strong>2.이용 경험에 대한 설문조사입니다.</strong><br>
      <a href="https://form.naver.com/edit/MUy-vD5jHDatr70kCN878Q" target="_blank">이용 경험 설문조사</a><br><br>
    </p>
    <p class="large-text"><strong>모두 마치셨습니다. 감사합니다.</strong></p>
    <!-- 마지막 페이지는 더 이상 다음 버튼이 필요 없을 수도 있음 -->
  </div>
</body>
</html>


